<!DOCTYPE HTML>
<!--
	Helios by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Soomin Shin</title>
		<meta charset="utf-8" />
		
		<meta property="og:type" content="website"/>
		<meta property="og:title" content="Portfolio_Shin_Soomin"/>
		<meta property="og:image:width" content="600" />
		<meta property="og:image:height" content="315" />
		<meta property="og:image" content="http://www.soominshinportfolio.com/mini/images/header.jpg"/>
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="homepage is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header" style="height: 0; min-height: 0;">

					<!-- Inner -->

					<!-- Nav -->
						<nav id="nav">
							<ul>
								<li><a href="index.html">Home</a></li>
								<li>
									<a href="#">Project list</a>
									<ul>
										<li><a href="./P2.html">Empathy in Human Robot Interaction</a></li>
										<li><a href="./P3.html">What information do people use when perceving others' emotions?</a></li>
										<li><a href="./P4.html">The different mechanism between Convolutional Neural Networks and Humans in Emotion Recognition</a></li>
										<li><a href="./P1.html">Sentiment analysis system for psychological examinaiton</a></li>
										
										<li><a href="./P5.html">Teaching Children Programming via robotics</a></li>
										<li><a href="./P7.html">Is block programming effective to adults when learning general programming languages?</a></li>
										<li><a href="./P9.html">Can machine learning agents learn a social behavior?</a></li>
										<li><a href="./P6.html">Works from internship program</a></li>
										<li><a href="./P8.html">Android application matching crowdfunding products to users based on their personality</a></li>
									</ul>
								</li>
								<li><a href="AboutMe.html">About Me</a></li>
							</ul>
						</nav>

				</div>

					<div class="wrapper style2">

			<article id="main" class="container special">
				
				<header style="padding-top: 10%">
					<h2><a> </a></h2>
				</header>
					<h3>
					Introduction
					</h3>
				<p>

						Having experienced first-hand the challenges my family faced coping with my younger brother’s mental health (ADHD and depression disorder) since elementary school, I have always been keenly interested in helping children with mental disorder and their families. Despite the increasing interest in mental well-being, psychiatric clinics in Korea are still not easily accessible to many people with mental disabilities due to financial and social issues. This has inspired me to pursue a PhD to develop a social robot that helps children who struggle with reading other people’s emotions, receive little psychological support, and have difficulty in social interactions. Through my PhD research, I aim to provide more affordable and accessible social robots with mental support functions for people to use as a home counselor in caring for their mind-wellbeing.

				</p>
				<h3>
					PhD Research Plans
				</h3>
				<p>
					To this end, my research objectives are twofold: 1) to enhance the emotional function of robots for them to interact and build relationships with children, and 2) teach robots the mechanisms of inferring human emotions accurately. I believe I will be able to achieve my goals in the Personal Robots Lab under Professor Breazeal as a doctorate. 
				</p>
				<p>
					For the first aim, I will extend my current research project, “Do We Feel Empathy toward a Robot?”, [2] to apply to children in unstructured environments. By eliciting empathy from children, robots will easily be able to establish a rapport with them. I will identify robots’ interactional performance with children by comparing two types: those with the function of eliciting empathy and those without it.
				</p>
				<p>
					Second, I plan to apply the Deep Neural Networks (DNNs) of holistic emotion inference to social robots. We can enhance emotional interactions in humans by teaching robots how to holistically infer emotions (e.g., using body cues, background information [1,3], and text [4]). These trained robots will provide more emotional support to children and even adults in need of emotional interactions.
				</p>
				<p>
					Moreover, the emotion recognition robot can serve as a substitute for an instructor teaching emotion to autistic children, such as how non-autistic people infer others’ emotions in the real world. Hence, if we can teach robots the mechanisms of how to read emotions as humans, they can be used to teach autistic children what information they should focus on to read emotions as non-autistic people.
				</p>
				<h3>
					Related Experience
				</h3>
				<i>
					Empathy In HRI
				</i>
				<p>
					Presently in [2] at Korea University, my research professor and I designed an experiment in which the participants commanded a robot to perform challenging tasks against its will. Here, we measured their physiological signals (e.g., GSR and PPG) to identify the participants' emotional fluctuation, through skin conductance using tonic EDA and heart rate variability using frequency domain. Our result showed that the participants were emotionally aroused when they forced the robot to perform the task and were emotionally relaxed when they observed the robot successfully complete the task. From this experiment, I learned that it is possible to make humans feel empathy toward a robot depending on its behaviors.
				</p>
				<i>
					Holistic Emotion Recognition
				</i>
				<p>
					Next, through my two research projects “Contextual Information Intensifies Emotion Perception” and the “Contextual Modulation of Affect: Comparing Humans and Deep Neural Networks” [1, 3], I found that the mechanisms of reading emotions are critically different between humans and computational models. For the human behavior experiments, we presented the images of people expressing natural emotions in the wild as two stimuli forms: body + face images, and full-context images including face, body, and their background information. The participants inferred the emotions of figures in the stimuli differently according to the contextual information, which did not depend on the place (e.g., funeral) or the situation (e.g., winning a trophy) but on the emotional expressions of the surrounding people. This phenomenon was evident when the participants evaluated the emotions of ambiguous facial expressions.
				</p>
				<p>
					To compare human and machines mechanisms, we ran the same stimuli in two DNN architectures: One was ResNet trained on AffectNet capturing facial expressions only and the other was the combination architecture of ResNet and AlexNet that grasped holistic information. Although DNN was trained to capture the holistic information in a static image, its inference results differed considerably from those of humans. This is because DNN was trained to extract the features of places and figures to infer holistic emotions, while humans were affected more greatly by the surrounding people’s emotional expressions.
				</p>
				<i>
					Sentiment Analysis in Text
				</i>
				<p>
					For my undergraduate thesis, I constructed a Python-based web psychological examination system that can automatically assess sentiment in the user’s bunch of text [4]. Since not everyone can easily visit a psychiatry clinic, I wanted to increase people’s chance to see their mind through a proper psychological assessment exam, not a pseudo-psycho exam. This led me to apply Thematic Apperception Test (TAT), which is widely used to measure people’s unconsciousness in a psychiatrist clinic. My Python-based system will enable people to take a specialized psychological exam and to learn about their personality through their answers, which will be analyzed by a computational sentiment analysis model.
				</p>
				<h3>
					Conclusion
				</h3>
				<p>
					Given my research background and experience, I hope to receive the supervision of Professor Breazeal during my PhD. Among her notable research works, I am especially intrigued by “Assessing Children’s Perceptions and Acceptance of a Social Robot.” I will contribute to this research by associating it with my idea of eliciting empathy f humans via social robots’ behaviors. While children were told stories by the social robot in this study, I want to analyze how they perceive the social robot through active mutual interaction with it. Professor Breazeal’s previous research on multimodalities (e.g., face, motion, and text) convinces me that I will be able to solidify my topics and successfully achieve my goals under her guidance, thereby contributing to the enhancement of children’s social interactions in the long run.
				</p>
				<h3>
					<i>
						Reference
					</i>
				</h3>
				<p>
					1.	Shin, S.M. “Contextual Information Intensifies Emotion Perception,” Advisor: Prof. Christian Wallraven, (In progress).
				</p>
				<p>
					2.	Shin, S.M. “Do We Feel Empathy toward a Robot?” Advisor: Prof. June Kang, (In preparation).
				</p>
				<p>
					3.	Shin, S.M. & Kim, D.Y. “Contextual modulation of affect: Comparing humans and deep neural networks,” ACM International Conference on Multimodal Interaction Workshop, Advisor: Prof. Christian Wallraven, 2022.
				</p>
				<p>
					4.	Shin, S.M. “DNNs base Personality Test Result Analysis System,” Poster presentation, Advisor: Prof. June Hwang, Korean Society for Internet Information,  Nov. 2018.
				</p>
			</article>

		</div>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>