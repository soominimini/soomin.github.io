<!DOCTYPE HTML>
<!--
	Helios by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Portfolio_emotionH</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9PP3T9W5Q9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-9PP3T9W5Q9');
</script>


</head>

<body class="no-sidebar is-preload">
	<div id="page-wrapper">

		<!-- Header -->
		<div id="header">

			<!-- Inner -->
			<div class="inner">
				<header>
					<h1><a id="logo"></a></h1>
				</header>
			</div>

			<!-- Nav -->
			<nav id="nav">
				<ul>
					<li><a href="index.html">Home</a></li>
					<li>
						<a href="#">Project list</a>
						<ul>
							<li><a href="./P2.html">Empathy in humans towards a robot</a></li>
							<li><a href="./P3.html">What information do people use when perceving others' emotions?</a></li>
							<li><a href="./P4.html">The different mechanism between Convolutional Neural Networks and Humans in Emotion Recognition</a></li>
							<li><a href="./P1.html">Sentiment analysis system for psychological examinaiton</a></li>
							
							<li><a href="./P5.html">Teaching children programming via robotics</a></li>
							<li><a href="./P7.html">Is block programming effective for adults when learning general programming languages?</a></li>
							<li><a href="./P9.html">Can machine learning agents learn a social behavior?</a></li>
							<li><a href="./P8.html">An Android application matches crowdfunding products to users based on their personality</a></li>
							<li><a href="./P6.html">works resulting from the internship program </a></li>
						</ul>
					</li>
					<!-- <li><a href="AboutMe.html">About Me</a></li> -->
				</ul>
			</nav>

		</div>

		<!-- Main -->
		<div class="wrapper style1">

			<div class="container" style="font-family: 'Times New Roman', Times, serif;">
				<article id="main" class="special">
					<header>
						<h2>What information do people use when perceving others' emotions?</h2>
						<p>
							<!-- Accepted paper at Frontiers in psychology -->
						</p>
					</header>

					<div class="row">
						<h3>Which picture do you think is more affected by surrounding information when inferring a
							person's emotion?</h3>
						<article class="col-6 col-12-mobile special">
							<div class="row">

								<article class="col-6 col-12-mobile special">
									<div id="cf3" style="position: relative" class="shadow">
										<img style="width: 450px;" src="images/my/p3/amusement.jpeg" />
										<div style="position: absolute; top: 0px;">
											<img class="top" style="width: 450px"
												src="images/my/p3/amusement_blur.jpeg" />
										</div>
									</div>
									<div id="cf3" style="position: relative" class="shadow">
										<img style="width: 450px;" src="images/my/p3/data_1.png" />
										<div style="position: absolute; top: 0px;">
											<img class="top" style="width: 450px"
												src="images/my/p3/data_2.png" />
										</div>
									</div>
									
								</article>
							</div>
						</article>
						<article class="col-5 col-12-mobile special">
							<h3>
								ROLE

							</h3>
							<p>
								1) Web programming for experiments
							</p>
							<p>
								2) Data collection, analysis
							</p>
							<p>
								3) Paper writing
							</p>

							<h3>
								SKILLS UTILIZED

							</h3>
							<p style="margin-bottom: 5%;">
								Coding(javaScript, php)
							</p>

						</article>
					</div>

					<section>

						<header>
							<h3>Purpose of this project</h3>
						</header>
						<p>
							When inferring the emotions of others, people rely heavily on contextual information. Importantly, 
							since emotions are often elicited in social contexts, the information present in the emotion expresser’s surroundings, 
							including situational context and emotional expression of other persons, will provide additional clues.
							Despite the fact that recent studies have focused on the impact of context on emotion perception, 
							researchers have mainly shed light on facial muscle configuration in emotion perception. 
							For those reasons, we designed experiments using the presence of contextual information in an effort to 
							examine the mechanism of holistic emotion perception.
						</p>
						<!-- <p>
									People use much contextual information when inferring other people's emotions. 
									Importantly, since emotions are often elicited in social contexts, the information present in the emotion expresser’s surroundings, including situational context and emotional expression of other persons, will provide additional clues. 
									To investigate such contextual effects on emotion perception, here, we probed participants’ evaluation of two categories of stimuli representing positive emotion: the first category contained pictures of emotional situations taken from the real world that had a precise positive evaluation and often involved several people, whereas the second retained only a central person of each stimulus, completely blurring out all expressor-external, contextual information. 
									Using valence and arousal judgments of both categories in a within-experiment design (<em>n</em>=42 participants), we found that contextual information elicited significantly intensified responses (higher valence and arousal) from participants. 
									Among the surrounding information, participants primarily were influenced by the emotions of immediately surrounding people to the target expresser.
								</p> -->
					</section>
					<section>
						<header>
							<h3>Dataset</h3>
						</header>
						<p>
							In this project, one of our primary goals was to collect pictures showing an emotional representation 
							that we could observe in the real world. 
							Many studies in the past conducted experiments by presenting controlled emotional expression stimuli 
							that were made under lab conditions. 
							In these studies, participants were asked to express emotions under the experimenters' instructions, 
							which means that participants inevitably represent emotions intentionally, 
							not naturally. After all, the posed stimuli make it only possible to assess certain exaggerated emotions in participants.
							For instance, AU 10 + AU 12 + AU 16 + AU 25 (Ekman & Friesen, 1978) for happiness, and AU 1 + AU 4 + AU 5 (Ekman & Friesen, 1978) 
							for sadness.
						</p>
						<p>
							To achieve the project's goal, we chose several news platforms as stimuli sources (e.g., AP, Reuters, Yonhap). 
							We excluded images of celebrities from these platforms, in particular, to avoid anchoring bias and posed facial expressions. 
							Since we targeted these platforms to investigate the "happiness" emotion, happiness-related keywords were searched on them. 
							Keywords were composed of a combination of behavior 
							(e.g., giggle, smile), target (e.g., child, family, student), and place (e.g., playground, amusement park).

						</p>
						<p>
							Due to a copyright issue, we only presented URLs of pictures we used to let people access and see the composition of stimuli.
							<a
								href="https://github.com/soominimini/dataset_link">https://github.com/soominimini/dataset_link</a>
						</p>
					</section>

					<section>
						<header>
							<h3>Experiment</h3>
						</header>
						<div class="row">

							<article class="col-10 col-12-mobile special">
								<a class="image fit"><img src="images/my/p3/exp_fig.jpg" /></a>
								<p>Figure 1</p>
							</article>
							<p>
								In this study, we presented two stimulus types: context-blurred and full-context stimuli. 
								We left a figure's body cues as intact 
								as possible and blurred all information except the one figure in the frame. 
								<br><br>
								For an assessment method, we utilized the Self-Assessment-Manikin (SAM) on a 7-scale. 
								We only provided valence and arousal dimensions in this experiment to eliminate the chances of 
								distracting participants by offering an irrelevant option.
							</p>
						</div>
						<section>

							<header>
								<h3>Result</h3>
							</header>
							<div class="row">
								
								<article class="col-10 col-12-mobile special">
									<a class="image fit"><img src="images/my/p3/ret_fig.jpg" /></a>
									<p>Figure 2. After subtracted from rated scores of full-context stimuli to
										context-blurred stimuli, calculated Bonferroni correction.
										
										
										<a class="image fit"><img src="images/my/p3/ret_fig2.jpg" /></a>
										<p>Figure 3</p>
								</article>

								<p>
									In this study, we discovered that people are affected by the emotional representation 
									besieging a target person when inferring that person's emotion. 
									This is far different from our primitive hypothesis that people utilize scenery information 
									(e.g., an amusement park, a funeral) to infer others' emotions.
									<br><br>
									Instead, people inferred emotions based on emotional states in peripheral areas. 
									The woman on the right side of Figure 1 was rated valence-negative when she was presented 
									along with the context (the woman on the left) than when she was presented alone. 
									In stark contrast, the woman on the left side of Figure 1 was assessed
									as more valence-positive when presented with the context.
	
									<br><br>
									Figure 3 shows a different aspect of the contextual effect. 
									The girl in Figure 3 was assessed as valence-positive when she was presented along with manifold people. 
									Not only is it affected by surrounding emotional states, 
									but it is also affected by the crowd-amplification-effect (Goldenberg et al., 2021) 
									and the presence of people's closeness (Greenaway et al., 2018).
								</p>
							</div>
						</section>
				</article>


			</div>

		</div>


	</div>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.dropotron.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>